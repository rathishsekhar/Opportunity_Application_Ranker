{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4a. Models - Word2Vec model\n",
    "\n",
    "Description for this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.0 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.1 Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to project directory\n",
    "\n",
    "os.chdir(Path(os.path.realpath(\"\")).resolve().parents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules that fetch or save the data\n",
    "\n",
    "from src.getter.load_application_and_opportunity import *\n",
    "from src.getter.save_application_and_opportunity import *\n",
    "\n",
    "# Gathering the data\n",
    "w2v_data_dictionary = get_interim_data(\"w2v_data_dictionary\")\n",
    "ppdata = get_interim_data(\"preprocesseddata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of column names that contains the names of the columns, if they belong to the job or candidate\n",
    "\n",
    "job_column = ['ExternalBriefDescription','ExternalDescription', 'Title', \n",
    "              'JobCategoryName']\n",
    "uid_column = ['OpportunityId', 'ApplicationId']\n",
    "can_column = [\n",
    "    'IsCandidateInternal',\n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria',\n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepName', \n",
    "    'StepGroup',\n",
    "    'pass_first_step'\n",
    "] # Column - StepId has been removed\n",
    "\n",
    "sel_column = ['IsRejected']\n",
    "\n",
    "# Defining list of columns based on the type of contents\n",
    "\n",
    "str_column = [\n",
    "    'ExternalBriefDescription', \n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName', \n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria', \n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepId', \n",
    "    'StepName', \n",
    "    'StepGroup'\n",
    "]\n",
    "bool_column = ['IsCandidateInternal', 'pass_first_step']\n",
    "float_column = ['Tag']\n",
    "\n",
    "# Defining list of columns based on the models\n",
    "\n",
    "model_names = [\"w2v\", \"bert\", \"dbert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the data\n",
    "\n",
    "ppdata = ppdata[uid_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying w2v vectors onto the ppdata_uid \n",
    "\n",
    "ppdata[\"opportunity__w2v_hstack\"] = ppdata['OpportunityId'].apply(lambda x : w2v_data_dictionary['job_opportunityid_w2v_dict_hstack'][x])\n",
    "ppdata[\"opportunity__w2v_vstack\"] = ppdata['OpportunityId'].apply(lambda x : w2v_data_dictionary['job_opportunityid_w2v_dict_vstack'][x])\n",
    "ppdata[\"candidate__w2v_hstack\"] = ppdata['ApplicationId'].apply(lambda x : w2v_data_dictionary['can_applicationid_w2v_dict_hstack'][x])\n",
    "ppdata[\"candidate__w2v_vstack\"] = ppdata['ApplicationId'].apply(lambda x : w2v_data_dictionary['can_applicationid_w2v_dict_vstack'][x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.2.1 Working on word2vec data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through experimentation, it was realized that the word2vec or as a matter of fact any langugage based vector need not be scalled as scalling would modify the information stored in the embeddings , we do not scale the data before PCA.  \n",
    "\n",
    "#### 4a.2.1.1 Creating functions that reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating function that creates arrays for calculating the cosine similarity \n",
    "def reduce_dimensionality(data, opp_uid_name, app_uid_name,  opportunity_stack_dict, candidate_stack_dict):\n",
    "     \"\"\"\n",
    "    Reduce the dimensionality of vectors using PCA, if horizontally stacked \n",
    "    (ignored if vertically stacked) and create arrays from the data used \n",
    "    further for similarity calculations\n",
    "    \n",
    "    Parameters:\n",
    "        candidate_vectors (pandas.DataFrame): Horizontally stacked Word2Vec \n",
    "        vectors for candidates\n",
    "        opportunity_vectors (pandas.DataFrame): Horizontally stacked Word2Vec \n",
    "        vectors for opportunities\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Transformed array of vectors with reduced dimensionality\n",
    "        if horizontally stacked else transformed array of vectors with same \n",
    "        dimensionality\n",
    "    \"\"\"\n",
    "     data__ = data[[opp_uid_name] + [app_uid_name]]\n",
    "     data__['opportunity_vectors'] = data__[opp_uid_name].apply(lambda x : opportunity_stack_dict[x])\n",
    "     data__['candidate_vectors'] = data__[app_uid_name].apply(lambda x : candidate_stack_dict[x])\n",
    "\n",
    "     opportunity__ = np.array(\n",
    "          [np.array(x) for x in data__['opportunity_vectors'].tolist()]\n",
    "        )\n",
    "    \n",
    "     candidate__ = np.array(\n",
    "          [np.array(x) for x in data__['candidate_vectors'].tolist()]\n",
    "        )\n",
    "\n",
    "    # Setting the number of dimensions as minimum shape\n",
    "     no_of_dimensions = min(candidate__.shape[1], opportunity__.shape[1])\n",
    "\n",
    "     if 'PCA' in dir():\n",
    "        pca = PCA(n_components = no_of_dimensions)\n",
    "     else:\n",
    "         from sklearn.decomposition import PCA \n",
    "         pca =  PCA(n_components = no_of_dimensions)\n",
    "\n",
    "     # Applying PCA \n",
    "     if candidate__.shape[1] >= opportunity__.shape[1]: \n",
    "          # Exporting pca.fit for app based requirement\n",
    "         pca_fit = pca.fit(candidate__)\n",
    "         save_app_data(pca_fit, 'candidate_w2v_pca_model')\n",
    "\n",
    "         app_array, opp_array = pca.fit_transform(candidate__), opportunity__\n",
    "     else:\n",
    "          # Exporting pca.fit for app based requirement\n",
    "         pca_fit = pca.fit(opportunity__)\n",
    "         save_app_data(pca_fit, 'opportunity_w2v_pca_model')\n",
    "\n",
    "         app_array, opp_array = candidate__, pca.fit_transform(opportunity__) \n",
    "    \n",
    "     app_pca_dict, opp_pca_dict = {}, {}\n",
    "     \n",
    "     for uid, vector in zip(data__[app_uid_name], app_array):\n",
    "         app_pca_dict[uid] = vector\n",
    "     \n",
    "     for uid, vector in zip(data__[opp_uid_name], opp_array):\n",
    "         opp_pca_dict[uid] = vector\n",
    "    \n",
    "     return opp_pca_dict, app_pca_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a.2.1.2 Deriving dimensionally reduced dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving dimensionally reduced dictionaries for opportunity ID\n",
    "opp__w2v_pca_hstack_dict, app__w2v_pca_hstack_dict = reduce_dimensionality(ppdata, \"OpportunityId\", \"ApplicationId\", w2v_data_dictionary['job_opportunityid_w2v_dict_hstack'], w2v_data_dictionary['can_applicationid_w2v_dict_hstack'])\n",
    "\n",
    "\n",
    "# Beware of using this, this functions overwrites the PCA pickle file - Use with caution\n",
    "# opp__w2v_pca_vstack_dict, app__w2v_pca_vstack_dict = reduce_dimensionality(ppdata, \"OpportunityId\", \"ApplicationId\", w2v_data_dictionary['job_opportunityid_w2v_dict_vstack'], w2v_data_dictionary['can_applicationid_w2v_dict_vstack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8473 110267\n"
     ]
    }
   ],
   "source": [
    "# Checking the dimensions after PCA\n",
    "\n",
    "print(len(opp__w2v_pca_hstack_dict), len(app__w2v_pca_hstack_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a.2.2.1 Creating functions that calculate cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top n-similar cosine vectors\n",
    "def pairwise_cosine(data, opp_uid_name, app_uid_name, opp_pca_dict, app_pca_dict):\n",
    "    '''\n",
    "    Compute pairwise cosine similarity between opportunity and application \n",
    "    vectors in DataFrame\n",
    "\n",
    "    Parameters:\n",
    "        data(pandas.DataFrame): Input DataFrame containg opportunity and \n",
    "        application UIDs. \n",
    "        opp_upd_name(str): Columns name with oppotunity IDs\n",
    "        app_uid_name(str): Columns name with applciation IDs\n",
    "        opp_pca_dict (dict): Dictionary mapping opportunity uids to the vectors\n",
    "        app_pca_dict (dict): Dictionary mapping application uids to the vectors\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame with columns \"OpportunityId\", \"ApplciationId and \n",
    "        cosine similarity\n",
    "    '''\n",
    "    data__ = data[[opp_uid_name] + [app_uid_name]]\n",
    "    data__['opportunity_vectors'] = data__[opp_uid_name].apply(lambda x : opp_pca_dict[x])\n",
    "    data__['candidate_vectors'] = data__[app_uid_name].apply(lambda x : app_pca_dict[x])\n",
    "\n",
    "    opportunity__ = np.array(\n",
    "          [np.array(x) for x in data__['opportunity_vectors'].tolist()]\n",
    "        )\n",
    "    \n",
    "    candidate__ = np.array(\n",
    "          [np.array(x) for x in data__['candidate_vectors'].tolist()]\n",
    "        )\n",
    "    \n",
    "    opportunity__ = (opportunity__/np.linalg.norm(opportunity__, axis = 1)[:, np.newaxis])\n",
    "    candidate__ = (candidate__/np.linalg.norm(candidate__, axis = 1)[:, np.newaxis])\n",
    "    \n",
    "    data__['row_similarity'] = [np.dot(row1, row2) for row1, row2 in zip(opportunity__, candidate__)]\n",
    "     \n",
    "    return data__[[opp_uid_name] + [app_uid_name] + ['row_similarity']]\n",
    "\n",
    "def topn_similar(opp_pca_dict, app_pca_dict, n = 3):\n",
    "    \"\"\"\n",
    "    Calculates top n most similar application IDs for a given opportunity ID\n",
    "\n",
    "    Parameters:\n",
    "        opp_pca_dict (dict): Dictionary mapping opportunity IDs to their \n",
    "        dimensionally reduced vectors. \n",
    "        app_pca_dict (dict): Dictionary mapping application IDs to their \n",
    "        dimensionally reduced vectors. \n",
    "        n(int, optional - default = 3): Number of top similar application IDs \n",
    "        to retrieve\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with keys as opportunity IDs pointing to value which is \n",
    "    a dictionary in itself. This dictionary contaings application IDs as keys \n",
    "    and similarity scores as values\n",
    "    \"\"\"\n",
    "    \n",
    "    similarity_dict = {}\n",
    "\n",
    "    for key_opp, val_opp in tqdm(opp_pca_dict.items(), desc = \"Application IDs: \", total = len(opp_pca_dict)):\n",
    "        \n",
    "        temp = {}\n",
    "\n",
    "        for key_app, val_app in app_pca_dict.items():\n",
    "            temp_value = np.dot(val_opp/np.linalg.norm(val_opp), val_app/np.linalg.norm(val_app))\n",
    "            temp[key_app] = temp_value\n",
    "        \n",
    "        sorteddict = sorted(temp.items(), key = lambda x: x[1], reverse = True)[:n]\n",
    "\n",
    "        similarity_dict[key_opp] = sorteddict\n",
    "    \n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a.2.2.2 Applying pariwise - cosine similarity and getting top n(=3 default) similar application IDs and similarity values for each opportunity ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opp__w2v_pca_vstack_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cosine-similarity pairwise\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cosine_similarity_w2v_opp_app_hstack \u001b[38;5;241m=\u001b[39m pairwise_cosine(ppdata, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpportunityId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplicationId\u001b[39m\u001b[38;5;124m\"\u001b[39m, opp__w2v_pca_hstack_dict, app__w2v_pca_hstack_dict)\n\u001b[0;32m----> 3\u001b[0m cosine_similarity_w2v_opp_app_vstack \u001b[38;5;241m=\u001b[39m pairwise_cosine(ppdata, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpportunityId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplicationId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mopp__w2v_pca_vstack_dict\u001b[49m, app__w2v_pca_vstack_dict)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'opp__w2v_pca_vstack_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Cosine-similarity pairwise\n",
    "cosine_similarity_w2v_opp_app_hstack = pairwise_cosine(ppdata, \"OpportunityId\", \"ApplicationId\", opp__w2v_pca_hstack_dict, app__w2v_pca_hstack_dict)\n",
    "cosine_similarity_w2v_opp_app_vstack = pairwise_cosine(ppdata, \"OpportunityId\", \"ApplicationId\", opp__w2v_pca_vstack_dict, app__w2v_pca_vstack_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Application IDs: 100%|██████████| 8473/8473 [2:34:07<00:00,  1.09s/it]  \n",
      "Application IDs:  20%|██        | 1715/8473 [22:51<1:32:24,  1.22it/s]"
     ]
    }
   ],
   "source": [
    "# Similarity dictionaries Space\n",
    "similarity_w2v_dict_opp_app_hstack = topn_similar(opp__w2v_pca_hstack_dict, app__w2v_pca_hstack_dict)\n",
    "similarity_w2v_dict_opp_app_vstack = topn_similar(opp__w2v_pca_vstack_dict, app__w2v_pca_vstack_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.2.3 Saving the similarity data - horizontally and vertically stacked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data \n",
    "# hstack\n",
    "save_processed_data(similarity_w2v_dict_opp_app_hstack, \"similarity_dict_w2v_hstack\")\n",
    "save_processed_data(cosine_similarity_w2v_opp_app_hstack, \"cosine_similarity_w2v_hstack\")\n",
    "\n",
    "#vstack\n",
    "save_processed_data(similarity_w2v_dict_opp_app_vstack, \"similarity_dict_w2v_vstack\")\n",
    "save_processed_data(cosine_similarity_w2v_opp_app_vstack, \"cosine_similarity_w2v_vstack\")\n",
    "\n",
    "#Saving the dimensionally reduced vectors for streamlit app output\n",
    "save_app_data(opp__w2v_pca_hstack_dict, 'opp__w2v_pca_hstack_dict')\n",
    "save_app_data(app__w2v_pca_hstack_dict, 'app__w2v_pca_hstack_dict')\n",
    "save_app_data(opp__w2v_pca_vstack_dict, 'opp__w2v_pca_vstack_dict')\n",
    "save_app_data(app__w2v_pca_vstack_dict, 'app__w2v_pca_vstack_dict')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

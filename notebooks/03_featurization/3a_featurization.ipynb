{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a. Featurizing the data - Word 2 Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.0 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.1.1 Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpportunityId</th>\n",
       "      <th>ApplicationId</th>\n",
       "      <th>ExternalBriefDescription</th>\n",
       "      <th>ExternalDescription</th>\n",
       "      <th>Title</th>\n",
       "      <th>JobCategoryName</th>\n",
       "      <th>IsRejected</th>\n",
       "      <th>IsCandidateInternal</th>\n",
       "      <th>BehaviorCriteria</th>\n",
       "      <th>MotivationCriteria</th>\n",
       "      <th>...</th>\n",
       "      <th>SkillCriteria__trnsfrmrpp</th>\n",
       "      <th>WorkExperiences__trnsfrmrpp</th>\n",
       "      <th>Educations__trnsfrmrpp</th>\n",
       "      <th>LicenseAndCertifications__trnsfrmrpp</th>\n",
       "      <th>Skills__trnsfrmrpp</th>\n",
       "      <th>Motivations__trnsfrmrpp</th>\n",
       "      <th>Behaviors__trnsfrmrpp</th>\n",
       "      <th>StepId__trnsfrmrpp</th>\n",
       "      <th>StepName__trnsfrmrpp</th>\n",
       "      <th>StepGroup__trnsfrmrpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MbzeABKVn06G8irkoHJeIg==</td>\n",
       "      <td>nTzdqGj020CYqTouPocGSg==</td>\n",
       "      <td>$16.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$16.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Call Cente...</td>\n",
       "      <td>Degree Some college Description None Graduatio...</td>\n",
       "      <td></td>\n",
       "      <td>ScaleValue 4 ScaleValueName Advanced Skill Clo...</td>\n",
       "      <td>Description Inspired to perform well by moneta...</td>\n",
       "      <td>Description Devoted to a task or purpose with ...</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7SPt0A57/kyzM9hE9vxDRg==</td>\n",
       "      <td>QVk5MFCZ70WvlZE9FzAW9g==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Coordinato...</td>\n",
       "      <td>Degree Diploma Description None GraduationMont...</td>\n",
       "      <td></td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Sales...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7SPt0A57/kyzM9hE9vxDRg==</td>\n",
       "      <td>I1kcPlAw3E+rqceh0qrutQ==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Direct Car...</td>\n",
       "      <td>Degree HIGH SCHOOL DIPLOMA Description None Gr...</td>\n",
       "      <td></td>\n",
       "      <td>ScaleValue 4 ScaleValueName Advanced Skill Cas...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zolSWBFjWESbfkj8AXLYwA==</td>\n",
       "      <td>VTCXZK6/ZUWJDpxTcm2CRg==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear 2019.0 JobTitle Package ...</td>\n",
       "      <td>Degree Associate in Early Description None Gra...</td>\n",
       "      <td></td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Cashi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zolSWBFjWESbfkj8AXLYwA==</td>\n",
       "      <td>I6KgcL0jdkG8wBnL1+BZ/g==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Warehouse ...</td>\n",
       "      <td>Degree Bachelor of Business Admin Description ...</td>\n",
       "      <td></td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Forkl...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              OpportunityId             ApplicationId  \\\n",
       "0  MbzeABKVn06G8irkoHJeIg==  nTzdqGj020CYqTouPocGSg==   \n",
       "1  7SPt0A57/kyzM9hE9vxDRg==  QVk5MFCZ70WvlZE9FzAW9g==   \n",
       "2  7SPt0A57/kyzM9hE9vxDRg==  I1kcPlAw3E+rqceh0qrutQ==   \n",
       "3  zolSWBFjWESbfkj8AXLYwA==  VTCXZK6/ZUWJDpxTcm2CRg==   \n",
       "4  zolSWBFjWESbfkj8AXLYwA==  I6KgcL0jdkG8wBnL1+BZ/g==   \n",
       "\n",
       "                            ExternalBriefDescription  \\\n",
       "0  $16.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "1  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "2  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "3  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "4  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "\n",
       "                                 ExternalDescription  \\\n",
       "0  <p><strong>$16.00 Per Hour</strong></p>\\n<p><s...   \n",
       "1  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "2  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "3  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "4  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "\n",
       "                         Title   JobCategoryName  IsRejected  \\\n",
       "0  Customer Service Specialist  Customer Service        True   \n",
       "1  Customer Service Specialist  Customer Service        True   \n",
       "2  Customer Service Specialist  Customer Service        True   \n",
       "3  Customer Service Specialist  Customer Service        True   \n",
       "4  Customer Service Specialist  Customer Service        True   \n",
       "\n",
       "   IsCandidateInternal                                   BehaviorCriteria  \\\n",
       "0                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "1                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "2                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "3                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "4                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "\n",
       "                                  MotivationCriteria  ...  \\\n",
       "0  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "1  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "2  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "3  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "4  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "\n",
       "                           SkillCriteria__trnsfrmrpp  \\\n",
       "0  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "1  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "2  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "3  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "4  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "\n",
       "                         WorkExperiences__trnsfrmrpp  \\\n",
       "0  EndMonth None EndYear None JobTitle Call Cente...   \n",
       "1  EndMonth None EndYear None JobTitle Coordinato...   \n",
       "2  EndMonth None EndYear None JobTitle Direct Car...   \n",
       "3  EndMonth None EndYear 2019.0 JobTitle Package ...   \n",
       "4  EndMonth None EndYear None JobTitle Warehouse ...   \n",
       "\n",
       "                              Educations__trnsfrmrpp  \\\n",
       "0  Degree Some college Description None Graduatio...   \n",
       "1  Degree Diploma Description None GraduationMont...   \n",
       "2  Degree HIGH SCHOOL DIPLOMA Description None Gr...   \n",
       "3  Degree Associate in Early Description None Gra...   \n",
       "4  Degree Bachelor of Business Admin Description ...   \n",
       "\n",
       "  LicenseAndCertifications__trnsfrmrpp  \\\n",
       "0                                        \n",
       "1                                        \n",
       "2                                        \n",
       "3                                        \n",
       "4                                        \n",
       "\n",
       "                                  Skills__trnsfrmrpp  \\\n",
       "0  ScaleValue 4 ScaleValueName Advanced Skill Clo...   \n",
       "1  ScaleValue 5 ScaleValueName Expert Skill Sales...   \n",
       "2  ScaleValue 4 ScaleValueName Advanced Skill Cas...   \n",
       "3  ScaleValue 5 ScaleValueName Expert Skill Cashi...   \n",
       "4  ScaleValue 5 ScaleValueName Expert Skill Forkl...   \n",
       "\n",
       "                             Motivations__trnsfrmrpp  \\\n",
       "0  Description Inspired to perform well by moneta...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                               Behaviors__trnsfrmrpp  \\\n",
       "0  Description Devoted to a task or purpose with ...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "         StepId__trnsfrmrpp StepName__trnsfrmrpp StepGroup__trnsfrmrpp  \n",
       "0  K8yQlic+/UiXxBMpOnAoLQ==              Decline              declined  \n",
       "1  K8yQlic+/UiXxBMpOnAoLQ==              Decline              declined  \n",
       "2  K8yQlic+/UiXxBMpOnAoLQ==              Decline              declined  \n",
       "3  K8yQlic+/UiXxBMpOnAoLQ==              Decline              declined  \n",
       "4  K8yQlic+/UiXxBMpOnAoLQ==              Decline              declined  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving to parent directory\n",
    "\n",
    "os.chdir(Path(os.path.realpath(\"\")).resolve().parents[1])\n",
    "\n",
    "# Importing the data gathering modules\n",
    "\n",
    "from src.getter.load_application_and_opportunity import *\n",
    "from src.getter.save_application_and_opportunity import *\n",
    "\n",
    "fdata = get_interim_data(\"preprocesseddata\")\n",
    "fdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.1.2 Defining column names for featurization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list containing names of the columns\n",
    "\n",
    "job_column = [\n",
    "    'ExternalBriefDescription',\n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName'\n",
    "]\n",
    "\n",
    "uid_column = ['OpportunityId', 'ApplicationId']\n",
    "\n",
    "can_column = [\n",
    "    'IsCandidateInternal',\n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria',\n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', 'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepName', \n",
    "    'Tag', \n",
    "    'StepGroup',\n",
    "    'pass_first_step'\n",
    "]\n",
    "\n",
    "sel_column = ['IsRejected']\n",
    "\n",
    "# Defining list of columns based on the type of contents\n",
    "\n",
    "str_column = [\n",
    "    'ExternalBriefDescription', \n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName', \n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria', \n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepId', \n",
    "    'StepName', \n",
    "    'StepGroup'\n",
    "]\n",
    "\n",
    "bool_column = ['IsCandidateInternal', 'pass_first_step']\n",
    "\n",
    "float_column = ['Tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.2 TFIDF weighted word2vec vectorization\n",
    "\n",
    "Let's use TFIDF weighted word2vec for generating the necessary features to measure similarity. \n",
    "To do this, let's generate two functions - tfidf_weighted_word2vec, which inputs the column name and the data to generate the TFIDF vocabulary, TFIDF's - idf values, and word2vec vocab:vector after training the data. \n",
    "The second function i.e. TFIDF w2v_vectorizer intakes all of the variables generated in the first function along and applies it to a particular text to achieve TFIDF weighted word to vec. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.2.1 Creating functions that derive TFIDF weighted word2vec information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2vbased_embedder(data, uid_column_name, str_column, bool_column, float_column):\n",
    "    \"\"\"\n",
    "    Embeds TF-IDF weighted Word2Vec for string columns and encodes and pads the\n",
    "    boolean float columns to finally concatenate into horizontally and \n",
    "    vertically stacked vectors.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): Input dataset.\n",
    "        uid_column_name (str): Name of the user ID column.\n",
    "        str_column (list): List of string column names.\n",
    "        bool_column (list): List of boolean column names.\n",
    "        float_column (list): List of float column names.\n",
    "        vector_dim (int): Dimension of the word vectors.\n",
    "\n",
    "    Returns:\n",
    "        dict_hstack (dict): Dictionary with user ID as keys and hstacked \n",
    "        vectors as values.\n",
    "        dict_vstack (dict): Dictionary with user ID as keys and vstacked\n",
    "          vectors as values.\n",
    "\n",
    "    \"\"\"\n",
    "    def tfidf_weighted_word2vec(data, colname, vector_dim = 768):\n",
    "        \"\"\"\n",
    "        Function generates necessary components to derive TF-IDF weighted Word2Vec\n",
    "        from an entire data column.    \n",
    "\n",
    "        Args:\n",
    "            data (pandas.DataFrame): Dataset containing columns text for converting \n",
    "            into word2vec\n",
    "            col_names (str) : Name of the target column on which the operation \n",
    "            needs to be performed\n",
    "\n",
    "        Returns: \n",
    "            w2v (dict) : Dictionary with keys as words and values as i.e. word2vec \n",
    "            model generated respective vectors\n",
    "            word2weight (dict) : Dictionary with words and their corresponding \n",
    "            TF-IDF weights \n",
    "            vocab(dict) : Vocabulary dictionary with word indices\n",
    "        \"\"\"\n",
    "\n",
    "        # Generating coldata\n",
    "        c = data[colname].tolist()\n",
    "        c = [str(x) for x in c]\n",
    "        coldata = []\n",
    "        \n",
    "        # Creating model and tokenizing words for the moedl\n",
    "        model = Word2Vec(\n",
    "            window = 2, min_count = 3, sg = 1, vector_size = vector_dim\n",
    "        )\n",
    "        \n",
    "        for x in c:\n",
    "            coldata.append(gensim.utils.simple_preprocess(x))\n",
    "\n",
    "        # Creating model vocabulary from the tokens and then training and \n",
    "        # later bundling into a dictionary\n",
    "        \n",
    "        model.build_vocab(coldata)\n",
    "        model.train(corpus_iterable=coldata, total_examples= model.corpus_count, \n",
    "                    epochs=model.epochs)\n",
    "        \n",
    "        w2v = dict(zip(model.wv.index_to_key, model.wv.vectors.round(3)))\n",
    "        \n",
    "        # Creating TFIDF vectorizer model\n",
    "        \n",
    "        tfidfvectorizer = TfidfVectorizer()\n",
    "        tfidfvectorizer.fit_transform(c)\n",
    "        vocab = tfidfvectorizer.vocabulary_.items()\n",
    "\n",
    "        # Generating word2weight dictionary of word and its TFIDF values\n",
    "        word2weight = [(w, round(tfidfvectorizer.idf_[i], 3)) \n",
    "                    for w, i in tfidfvectorizer.vocabulary_.items()]\n",
    "        word2weight  = dict(word2weight)\n",
    "\n",
    "        return w2v, word2weight, vocab\n",
    "\n",
    "    def tfidfw2v_vectorizer(text, w2v, word2weight, vector_dim = 768):\n",
    "        \"\"\"\n",
    "\n",
    "        Perform TF-IDF weighted Word2Vec embdedding on a text column in a DataFrame\n",
    "        using the word2vec related components provided on the text. \n",
    "\n",
    "        Function calculates the TFIDF (from scikit-learn's TFIDFfVectorizer) \n",
    "        weighted word2vec (from gensim.Word2Vec) as per the following formulae:\n",
    "        Tfidf w2v (w1,w2..) = \n",
    "        (tfidf(w1) * w2v(w1) + tfidf(w2) * w2v(w2) + …)/(tfidf(w1) + tfidf(w2) + …\n",
    "        from various inputs. \n",
    "\n",
    "        Args:\n",
    "            text (str): Input text for which to calculate the TF-IDF weighted \n",
    "            Word2Vec vector.\n",
    "            w2v (dict): Dictionary with keys as words and values as their \n",
    "            respective vectors.\n",
    "            word2weight (dict): Dictionary with words and their corresponding\n",
    "            TF-IDF  weights.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: TF-IDF weighted Word2Vec vector for the input text.\n",
    "\n",
    "        \"\"\"\n",
    "        words = text.split() \n",
    "\n",
    "        if len(words) == 0:\n",
    "            \n",
    "            return np.zeros(vector_dim) \n",
    "\n",
    "        else:\n",
    "            numerator_vector = np.zeros(vector_dim)\n",
    "            denominator_value = 0.0\n",
    "            \n",
    "            for word in words:\n",
    "                \n",
    "                if word in w2v.keys() and word in word2weight.keys():\n",
    "                    \n",
    "                    numerator_val = words.count(word)*word2weight[word]*w2v[word]\n",
    "                    numerator_vector += numerator_val\n",
    "                \n",
    "                    denominator_val = words.count(word)*word2weight[word]\n",
    "                    denominator_value += denominator_val\n",
    "            \n",
    "            if denominator_value == 0.0:\n",
    "                \n",
    "                return np.zeros(vector_dim)\n",
    "        \n",
    "            else: \n",
    "                \n",
    "                return np.round(numerator_vector/denominator_value, 3)\n",
    "    \n",
    "    # Defining functions that encode and pad boolean and float values\n",
    "\n",
    "    def encode_and_pad_boolean_columns(fdata, bool_column, vector_dim = 768):\n",
    "        \"\"\"\n",
    "        Encode bookean columns in a pandas DataFrame using OneHot Encoder\n",
    "        \n",
    "        Args:\n",
    "            fdata (pandas DataFrame): upon whose boolean columns the encoding is to \n",
    "            executed\n",
    "\n",
    "            bool_column (list): List containing the boolean columns names to be \n",
    "            encoded\n",
    "\n",
    "            vector_dim (int): Dimension of the w2v_vectors\n",
    "        \n",
    "        Returns:\n",
    "            None, modifies the DataFrame in place adding new columns with one hot \n",
    "            encoded data\n",
    "        \n",
    "        \"\"\"\n",
    "        onehotencoder = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')\n",
    "        \n",
    "        for colname in bool_column:\n",
    "            fdata[colname + \"__w2v\"] = [\n",
    "                np.pad(x,  \n",
    "                    (0, vector_dim - (len(x) % vector_dim)), \n",
    "                    'constant') for x in onehotencoder.fit_transform(\n",
    "                        np.reshape(np.array(fdata[colname]), (-1, 1))\n",
    "                        )\n",
    "                        ]\n",
    "\n",
    "    def pad_float_columns(fdata, float_column, vector_dim = 768):\n",
    "        \"\"\"\n",
    "        Pads the specified float columns in the fdata pandas DataFrame so that the\n",
    "        final value has a length equal to vector_dim\n",
    "\n",
    "        Args:\n",
    "            fdata (pandas DataFrame): Data frame containing the float value\n",
    "            float_column (list): List of column names containig the float data\n",
    "            vector_dim (int): Dimension of the vector the columns will be padded\n",
    "\n",
    "        Returns:\n",
    "            None: Converts/ modifies the data and generates the new columns\n",
    "        \"\"\"\n",
    "        for colname in float_column:\n",
    "            fdata[colname + \"__w2v\"] = [np.pad(\n",
    "                x, \n",
    "                (0, vector_dim - (len(x) % vector_dim)), \n",
    "                'constant'\n",
    "            ) for x in (np.reshape(\n",
    "                np.array(fdata[colname]), (-1, 1)\n",
    "            ))]\n",
    "            \n",
    "    def hstacker(row_arrays):\n",
    "        \"\"\"\n",
    "        Function that concatenates each of the column data for each row\n",
    "        \"\"\"\n",
    "        return np.concatenate(row_arrays)\n",
    "\n",
    "    def vstacker(row_arrays):\n",
    "        \"\"\"\n",
    "        Gives the mean vector for the vectors in columns row-wise\n",
    "        \"\"\"\n",
    "        return np.mean(row_arrays)\n",
    "    \n",
    "    # Gathering the data and dropping duplicates\n",
    "    data__ = data[[uid_column_name]+ [x + \"__w2vpp\" for x in str_column] + bool_column + float_column]\n",
    "\n",
    "    # Applying encode_pad_boolean_columns and pad_float_columns \n",
    "\n",
    "    encode_and_pad_boolean_columns(data__, bool_column)\n",
    "    pad_float_columns(data__, float_column)\n",
    "\n",
    "     # Gathering and applying BERT base embedded vector for opportunity columns\n",
    "    \n",
    "    dict_hstack = {}\n",
    "    dict_vstack = {}\n",
    "\n",
    "    # Gathering string data only along with uid_column_name\n",
    "    w2v_dict, word2weight_dict = {}, {}\n",
    "    for colname in  str_column:\n",
    "        w2v, word2weight, vocab = tfidf_weighted_word2vec(data__, colname + \"__w2vpp\")\n",
    "        \n",
    "        w2v_dict[colname + \"__w2vpp\"] = w2v\n",
    "        word2weight_dict[colname + \"__w2vpp\"] = word2weight\n",
    "\n",
    "        data__[colname + \"__w2v\"] = data__[colname + \"__w2vpp\"].apply(lambda x: tfidfw2v_vectorizer(x, w2v, word2weight))\n",
    "    \n",
    "\n",
    "    data__[uid_column_name + \"__w2v_hstack\"] = data__[[m + \"__w2v\" for m in str_column + bool_column + float_column]].apply(hstacker, axis = 1)\n",
    "    data__[uid_column_name + \"__w2v_vstack\"] = data__[[m + \"__w2v\" for m in str_column + bool_column + float_column]].apply(vstacker, axis = 1)\n",
    "    \n",
    "    for index, row in data__.iterrows():\n",
    "        dict_hstack[data__.at[index, uid_column_name]] = data__.at[index, uid_column_name + \"__w2v_hstack\"]\n",
    "        dict_vstack[data__.at[index, uid_column_name]] = data__.at[index, uid_column_name + \"__w2v_vstack\"]\n",
    "    \n",
    "    # Saving w2v model components for applications\n",
    "    if uid_column_name == 'ApplicationId':        \n",
    "        save_app_data(w2v_dict, uid_column_name + '_w2v_dict')\n",
    "        save_app_data(word2weight_dict, uid_column_name + '_word2weight_dict')    \n",
    "    \n",
    "    return dict_hstack, dict_vstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.2.2 Executing the modelbased_embedder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering arguments for the w2vbased_embedder function for Opportunity columns\n",
    "# data = fdata\n",
    "uid_column_name = 'OpportunityId'\n",
    "str_col = [x for x in job_column if x in str_column]\n",
    "bool_col = [x for x in job_column if x in bool_column]\n",
    "float_col = [x for x in job_column if x in float_column]\n",
    "\n",
    "job_opportunityid_w2v_dict_hstack, job_opportunityid_w2v_dict_vstack = w2vbased_embedder(fdata, uid_column_name, str_col, bool_col, float_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering arguments for the modelbased_embedder function for Candidate columns\n",
    "# data = fdata\n",
    "uid_column_name = 'ApplicationId'\n",
    "str_col = [x for x in can_column if x in str_column]\n",
    "bool_col = [x for x in can_column if x in bool_column]\n",
    "float_col = [x for x in can_column if x in float_column]\n",
    "\n",
    "# Running the modelbased_embedder function\n",
    "can_applicationid_w2v_dict_hstack, can_applicationid_w2v_dict_vstack = w2vbased_embedder(fdata, uid_column_name, str_col, bool_col, float_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.3 Saving data for futher analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing modules that save the data \n",
    "\n",
    "from src.getter.save_application_and_opportunity import *\n",
    "\n",
    "# Adding dictionaries into the variables for pickle\n",
    "# Creating dictionary\n",
    "w2v_dict = {}\n",
    "\n",
    "# Adding dictionaries\n",
    "w2v_dict[\n",
    "    'job_opportunityid_w2v_dict_hstack'\n",
    "    ] = job_opportunityid_w2v_dict_hstack\n",
    "w2v_dict[\n",
    "    'can_applicationid_w2v_dict_hstack'\n",
    "    ] = can_applicationid_w2v_dict_hstack\n",
    "\n",
    "w2v_dict[\n",
    "    'job_opportunityid_w2v_dict_vstack'\n",
    "    ] = job_opportunityid_w2v_dict_vstack\n",
    "w2v_dict[\n",
    "    'can_applicationid_w2v_dict_vstack'\n",
    "    ] = can_applicationid_w2v_dict_vstack\n",
    "\n",
    "# Saving variables dictionary\n",
    "\n",
    "save_interim_data(w2v_dict, \"w2v_data_dictionary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

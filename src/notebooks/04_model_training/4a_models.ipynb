{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4a. Models - Word 2 Vec model\n",
    "\n",
    "Description for this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.0 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.1 Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to project directory\n",
    "\n",
    "os.chdir(Path(os.path.realpath(\"\")).resolve().parents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules that fetch the data\n",
    "\n",
    "from src.getter.load_application_and_opportunity import get_interim_data\n",
    "\n",
    "# Gathering the data\n",
    "\n",
    "featurizeddata_w2v = get_interim_data(\"featurizeddata_w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of column names that contains the names of the columns, if they belong to the job or candidate\n",
    "\n",
    "job_column = ['ExternalBriefDescription','ExternalDescription', 'Title', \n",
    "              'JobCategoryName']\n",
    "uid_column = ['OpportunityId', 'ApplicationId']\n",
    "can_column = [\n",
    "    'IsCandidateInternal',\n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria',\n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepName', \n",
    "    'StepGroup',\n",
    "    'pass_first_step'\n",
    "] # Column - 'Tag' Will be added later, StepId has been removed\n",
    "\n",
    "sel_column = ['IsRejected']\n",
    "\n",
    "# Defining list of columns based on the type of contents\n",
    "\n",
    "str_column = [\n",
    "    'ExternalBriefDescription', \n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName', \n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria', \n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepId', \n",
    "    'StepName', \n",
    "    'StepGroup'\n",
    "]\n",
    "bool_column = ['IsCandidateInternal', 'pass_first_step']\n",
    "float_column = ['Tag']\n",
    "\n",
    "# Defining list of columns based on the models\n",
    "\n",
    "model_names = [\"w2v\", \"bert\", \"dbert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering necessary arrays and applying Standard Scaller\n",
    "\n",
    "standardscaler = StandardScaler(copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top n-similar cosine vectors\n",
    "def n_pairwise_cosine_similar(matrix_1, matrix_2, n = 3):\n",
    "\n",
    "    '''\n",
    "    Returns diagonal values of cosine similarity and list of index containing \n",
    "    that top n similar cosine\n",
    "\n",
    "    Args:\n",
    "        matrix_1 (numpy array: 2D): Array containing vectors whose similarity \n",
    "        is to be checked\n",
    "        matrix_2 (numpy array: 2D): Array with which the similarity is to be \n",
    "        compared to\n",
    "        \n",
    "    n (int, default: 3): number of top similar values to be found\n",
    "\n",
    "    Returns:\n",
    "    diag_cosine_similarity (numpy array): Direct cosine similarity between \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    matrix_1 = (matrix_1/np.linalg.norm(matrix_1, axis = 1)[:, np.newaxis])\n",
    "    matrix_2 = (matrix_2/np.linalg.norm(matrix_2, axis = 1)[:, np.newaxis])\n",
    "\n",
    "    # Moving matrices to GPU\n",
    "    device = torch.device(\n",
    "        \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "    similarity_dict = {}\n",
    "    cosine_similarity = {}\n",
    "\n",
    "    for index_1, values_1 in tqdm(\n",
    "        enumerate(matrix_1), desc = \"Processing\", total = len(matrix_1)\n",
    "    ):\n",
    "        temp = {}\n",
    "    \n",
    "        for index_2, values_2 in enumerate(matrix_2):\n",
    "            temp_value = np.dot(values_1, values_2)\n",
    "\n",
    "            if index_1 == index_2:\n",
    "                cosine_similarity[index_1] = temp_value\n",
    "                \n",
    "            temp[index_2] = temp_value\n",
    "\n",
    "        sorteddict = sorted(\n",
    "            temp.items(), \n",
    "            key = lambda x: x[1], \n",
    "            reverse = True\n",
    "        )[:n]\n",
    "        \n",
    "        similarity_dict[index_1] = sorteddict #.keys() if keys are wanted\n",
    "    \n",
    "    return cosine_similarity, similarity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.2.1 Working on word2vec data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through experimentation, it was realized that the word2vec or as a matter of fact any langugage based vector need not be scalled as scalling would modify the information stored in the embeddings , we do not scale the data before PCA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving arrays for w2v vectors - horizontally stacked\n",
    "\n",
    "opportunity__w2v_hstack = np.array(\n",
    "    [np.array(x) for x in featurizeddata_w2v['opportunity__w2v_hstack']]\n",
    ")\n",
    "\"\"\"\n",
    "standardscaler.fit_transform(opportunity__w2v) - Experiment to see if minmax \n",
    "scalling affects the similarity means\n",
    "\"\"\"\n",
    "\n",
    "candidate__w2v_hstack = np.array(\n",
    "    [np.array(x) for x in featurizeddata_w2v['candidate__w2v_hstack']]\n",
    ")\n",
    "\"\"\"\n",
    "standardscaler.fit_transform(candidate__w2v) - Experiment to see if minmax \n",
    "scalling affetst the similarity means\n",
    "\"\"\"\n",
    "\n",
    "# Deriving array for w2v vectors - Vertically stacked\n",
    "\n",
    "opportunity__w2v_vstack = np.array(\n",
    "    [np.array(x) for x in featurizeddata_w2v['opportunity__w2v_vstack']]\n",
    ")\n",
    "candidate__w2v_vstack = np.array(\n",
    "    [np.array(x) for x in featurizeddata_w2v['candidate__w2v_vstack']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the dimensionality of horizontally stacked w2v vectors through PCA\n",
    "\n",
    "no_of_dimensions = min(\n",
    "    candidate__w2v_hstack.shape[1], opportunity__w2v_hstack.shape[1]\n",
    ")\n",
    "\n",
    "pca = PCA(n_components = no_of_dimensions, copy = False)\n",
    "\n",
    "if candidate__w2v_hstack.shape[1] >= opportunity__w2v_hstack.shape[1]:\n",
    "    candidate__w2v_hstack = pca.fit_transform(candidate__w2v_hstack)\n",
    "else:\n",
    "    opportunity__w2v_hstack = pca.fit_transform(opportunity__w2v_hstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110267, 2048) (110267, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Checking the dimensions after PCA\n",
    "\n",
    "print(candidate__w2v_hstack.shape, opportunity__w2v_hstack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 110267/110267 [7:41:51<00:00,  3.98it/s] \n"
     ]
    }
   ],
   "source": [
    "# Running the n_pairwise_cosine_similar func for horizontally stacked vectors\n",
    "\n",
    "(\n",
    "    cosine_similarity__w2v_hstack, \n",
    "    similarity_dict__w2v_hstack\n",
    ") = n_pairwise_cosine_similar(\n",
    "    opportunity__w2v_hstack, candidate__w2v_hstack, n = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 110267/110267 [4:03:37<00:00,  7.54it/s] \n"
     ]
    }
   ],
   "source": [
    "# Running the n_pairwise_cosine_similar func for vertically stacked vectors\n",
    "\n",
    "(\n",
    "    cosine_similarity__w2v_vstack, similarity_dict__w2v_vstack\n",
    ") = n_pairwise_cosine_similar(\n",
    "    opportunity__w2v_vstack, candidate__w2v_vstack, n = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a.2.2 Saving the similarity data - horizontally and vertically stacked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dictionaries into the variables for pickle\n",
    "similarity_w2v = {}\n",
    "\n",
    "# Adding dictionaries\n",
    "similarity_w2v[\"cosine_similarity__w2v_hstack\"] = cosine_similarity__w2v_hstack\n",
    "similarity_w2v[\"similarity_dict__w2v_hstack\"] = similarity_dict__w2v_hstack\n",
    "\n",
    "similarity_w2v[\"cosine_similarity__w2v_vstack\"] = cosine_similarity__w2v_vstack\n",
    "similarity_w2v[\"similarity_dict__w2v_vstack\"] = similarity_dict__w2v_vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data - Gathering necessary libraries\n",
    "\n",
    "from src.getter.save_application_and_opportunity import save_processed_data\n",
    "\n",
    "# Saving the data \n",
    "save_processed_data(similarity_w2v, \"similarity_dict_w2v\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

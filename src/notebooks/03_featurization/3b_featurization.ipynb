{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b. Featurizing the data - BERT based uncased model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b.1.1 Gathering data"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 1,

   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rathish/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk; nltk.download(\"punkt\")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpportunityId</th>\n",
       "      <th>ApplicationId</th>\n",
       "      <th>ExternalBriefDescription</th>\n",
       "      <th>ExternalDescription</th>\n",
       "      <th>Title</th>\n",
       "      <th>JobCategoryName</th>\n",
       "      <th>IsRejected</th>\n",
       "      <th>IsCandidateInternal</th>\n",
       "      <th>BehaviorCriteria</th>\n",
       "      <th>MotivationCriteria</th>\n",
       "      <th>...</th>\n",
       "      <th>SkillCriteria__mbertpp</th>\n",
       "      <th>WorkExperiences__mbertpp</th>\n",
       "      <th>Educations__mbertpp</th>\n",
       "      <th>LicenseAndCertifications__mbertpp</th>\n",
       "      <th>Skills__mbertpp</th>\n",
       "      <th>Motivations__mbertpp</th>\n",
       "      <th>Behaviors__mbertpp</th>\n",
       "      <th>StepId__mbertpp</th>\n",
       "      <th>StepName__mbertpp</th>\n",
       "      <th>StepGroup__mbertpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MbzeABKVn06G8irkoHJeIg==</td>\n",
       "      <td>nTzdqGj020CYqTouPocGSg==</td>\n",
       "      <td>$16.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$16.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Call Cente...</td>\n",
       "      <td>Degree Some college Description None Graduatio...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 4 ScaleValueName Advanced Skill Clo...</td>\n",
       "      <td>Description Inspired to perform well by moneta...</td>\n",
       "      <td>Description Devoted to a task or purpose with ...</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7SPt0A57/kyzM9hE9vxDRg==</td>\n",
       "      <td>QVk5MFCZ70WvlZE9FzAW9g==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Coordinato...</td>\n",
       "      <td>Degree Diploma Description None GraduationMont...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Sales</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7SPt0A57/kyzM9hE9vxDRg==</td>\n",
       "      <td>I1kcPlAw3E+rqceh0qrutQ==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Direct Car...</td>\n",
       "      <td>Degree HIGH SCHOOL DIPLOMA Description None Gr...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 4 ScaleValueName Advanced Skill Cash</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zolSWBFjWESbfkj8AXLYwA==</td>\n",
       "      <td>VTCXZK6/ZUWJDpxTcm2CRg==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear 2019.0 JobTitle Package ...</td>\n",
       "      <td>Degree Associate in Early Description None Gra...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Cashier</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zolSWBFjWESbfkj8AXLYwA==</td>\n",
       "      <td>I6KgcL0jdkG8wBnL1+BZ/g==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Warehouse ...</td>\n",
       "      <td>Degree Bachelor of Business Admin Description ...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Forklift</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              OpportunityId             ApplicationId  \\\n",
       "0  MbzeABKVn06G8irkoHJeIg==  nTzdqGj020CYqTouPocGSg==   \n",
       "1  7SPt0A57/kyzM9hE9vxDRg==  QVk5MFCZ70WvlZE9FzAW9g==   \n",
       "2  7SPt0A57/kyzM9hE9vxDRg==  I1kcPlAw3E+rqceh0qrutQ==   \n",
       "3  zolSWBFjWESbfkj8AXLYwA==  VTCXZK6/ZUWJDpxTcm2CRg==   \n",
       "4  zolSWBFjWESbfkj8AXLYwA==  I6KgcL0jdkG8wBnL1+BZ/g==   \n",
       "\n",
       "                            ExternalBriefDescription  \\\n",
       "0  $16.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "1  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "2  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "3  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "4  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "\n",
       "                                 ExternalDescription  \\\n",
       "0  <p><strong>$16.00 Per Hour</strong></p>\\n<p><s...   \n",
       "1  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "2  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "3  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "4  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "\n",
       "                         Title   JobCategoryName  IsRejected  \\\n",
       "0  Customer Service Specialist  Customer Service        True   \n",
       "1  Customer Service Specialist  Customer Service        True   \n",
       "2  Customer Service Specialist  Customer Service        True   \n",
       "3  Customer Service Specialist  Customer Service        True   \n",
       "4  Customer Service Specialist  Customer Service        True   \n",
       "\n",
       "   IsCandidateInternal                                   BehaviorCriteria  \\\n",
       "0                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "1                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "2                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "3                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "4                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "\n",
       "                                  MotivationCriteria  ...  \\\n",
       "0  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "1  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "2  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "3  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "4  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "\n",
       "                              SkillCriteria__mbertpp  \\\n",
       "0  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "1  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "2  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "3  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "4  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "\n",
       "                            WorkExperiences__mbertpp  \\\n",
       "0  EndMonth None EndYear None JobTitle Call Cente...   \n",
       "1  EndMonth None EndYear None JobTitle Coordinato...   \n",
       "2  EndMonth None EndYear None JobTitle Direct Car...   \n",
       "3  EndMonth None EndYear 2019.0 JobTitle Package ...   \n",
       "4  EndMonth None EndYear None JobTitle Warehouse ...   \n",
       "\n",
       "                                 Educations__mbertpp  \\\n",
       "0  Degree Some college Description None Graduatio...   \n",
       "1  Degree Diploma Description None GraduationMont...   \n",
       "2  Degree HIGH SCHOOL DIPLOMA Description None Gr...   \n",
       "3  Degree Associate in Early Description None Gra...   \n",
       "4  Degree Bachelor of Business Admin Description ...   \n",
       "\n",
       "  LicenseAndCertifications__mbertpp  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                              None   \n",
       "4                              None   \n",
       "\n",
       "                                     Skills__mbertpp  \\\n",
       "0  ScaleValue 4 ScaleValueName Advanced Skill Clo...   \n",
       "1     ScaleValue 5 ScaleValueName Expert Skill Sales   \n",
       "2    ScaleValue 4 ScaleValueName Advanced Skill Cash   \n",
       "3   ScaleValue 5 ScaleValueName Expert Skill Cashier   \n",
       "4  ScaleValue 5 ScaleValueName Expert Skill Forklift   \n",
       "\n",
       "                                Motivations__mbertpp  \\\n",
       "0  Description Inspired to perform well by moneta...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                  Behaviors__mbertpp  \\\n",
       "0  Description Devoted to a task or purpose with ...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "            StepId__mbertpp StepName__mbertpp StepGroup__mbertpp  \n",
       "0  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "1  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "2  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "3  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "4  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },

     "execution_count": 2,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloc ='/Users/rathish/Documents/Projects/Opportunity_Application_Ranker/inputs/data'\n",
    "fdata = pd.read_pickle(dataloc + '/interim/preprocesseddata.pkl')\n",
    "fdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b.1.2 Defining column names for featurization "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/notebooks/03_featurization/3b_featurization.ipynb
   "execution_count": 3,
=======

   "execution_count": 11,

   "execution_count": 23,

>>>>>>> 20ba1f8c5294aff0874b91a3115424430b0b645b:notebooks/3b_featurization.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list containing names of the columns\n",
    "\n",
    "job_column = [\n",
    "    'ExternalBriefDescription',\n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName'\n",
    "]\n",
    "\n",
    "uid_column = ['OpportunityId', 'ApplicationId']\n",
    "\n",
    "# Column - 'Tag' Will be added later\n",
    "can_column = [\n",
    "    'IsCandidateInternal',\n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria',\n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepId', \n",
    "    'StepName', \n",
    "    'StepGroup',\n",
    "    'pass_first_step'\n",
    "] \n",
    "\n",
    "sel_column = ['IsRejected']\n",
    "\n",
    "# Defining list of columns based on the type of contents\n",
    "\n",
    "str_column = [\n",
    "    'ExternalBriefDescription', \n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName', \n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria', \n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepId', \n",
    "    'StepName', \n",
    "    'StepGroup'\n",
    "]\n",
    "\n",
    "bool_column = ['IsCandidateInternal', 'pass_first_step']\n",
    "\n",
    "float_column = ['Tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b.2 Generating embeddings using transformer based large language models\n",
    "### 3b.2.1 Gathering necessary data for BERT based models"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/notebooks/03_featurization/3b_featurization.ipynb
   "execution_count": 4,
=======

   "execution_count": 12,

>>>>>>> 20ba1f8c5294aff0874b91a3115424430b0b645b:notebooks/3b_featurization.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering necessary columns of data that would be treated with bert models\n",
    "\n",
    "fdata['opportunity__str'] = fdata[[m + \"__bertpp\" \n",
    "                                   for m in job_column if m in str_column]\n",
    "                                   ].agg(\" \".join, axis = 1).tolist()\n",
    "\n",
    "fdata['candidate__str'] = fdata[[m + \"__bertpp\" \n",
    "                                 for m in can_column if m in str_column]\n",
    "                                 ].agg( \" \".join, axis = 1).tolist()\n",
    "\n",
    "\n",
    "# Applying OneHotEncoder for boolean columns\n",
    "\n",
    "onehotencoder = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')\n",
    "\n",
    "for colname in bool_column:\n",
    "    fdata[colname + \"__bert\"] = list(onehotencoder.fit_transform(\n",
    "        np.reshape(np.array(fdata[colname]), (-1, 1))\n",
    "        )\n",
    "    ) \n",
    "    \n",
    "\n",
    "# Gathering floatcolumn\n",
    "\n",
    "for colname in float_column:\n",
    "    fdata[colname + \"__bert\"] = list(np.reshape(\n",
    "        np.array(fdata[colname]), (-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b.2.2 Observations on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was observed in our EDA that there were only 8473 opportunities, which implies the text in the string columns are likely to be repeated for same jobs. Also, even though the the applicaiton ID is unique, it is likely that these same candidate with same candidate details may have applied for multiple jobs. In order to reduce the time and space capacities, lets check if the string columns when put together contains any duplicates. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/notebooks/03_featurization/3b_featurization.ipynb
   "execution_count": 5,
=======

   "execution_count": 13,

>>>>>>> 20ba1f8c5294aff0874b91a3115424430b0b645b:notebooks/3b_featurization.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     101794\n",
      "False      8473\n",
      "Name: count, dtype: int64 candidate__str\n",
      "False    109666\n",
      "True        601\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110267"
      ]
     },
<<<<<<< HEAD:src/notebooks/03_featurization/3b_featurization.ipynb
     "execution_count": 5,
=======

     "execution_count": 13,

>>>>>>> 20ba1f8c5294aff0874b91a3115424430b0b645b:notebooks/3b_featurization.ipynb
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "job_data = fdata[job_column + [\"OpportunityId\"]].duplicated()\n",
    "\n",
    " # ApplicationID ommitted as it was unique for all values\n",
    "\n",
    "can_data = fdata['candidate__str'].duplicated()\n",
    "\n",
    "print(job_data.value_counts(),  can_data.value_counts())\n",
    "fdata.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With so many (about 90%) duplicate values in candidate opportunities, it is prudent to therefore pass non-duplicates to the BERT and then associate the embeddings back to data.\n",
    "\n",
    "There wouldn't be significant time improvements(a reduction around 0.6% in the reduction of values) when pass non-duplicates to the BERT in case of the candidate textual information, so we do not drop duplicates, in this case. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/notebooks/03_featurization/3b_featurization.ipynb
   "execution_count": 6,
=======

   "execution_count": 14,

>>>>>>> 20ba1f8c5294aff0874b91a3115424430b0b645b:notebooks/3b_featurization.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_job_data_bert = fdata[[\"OpportunityId\"] + \n",
    "                          [m + \"__bertpp\" \n",
    "                           for m in job_column \n",
    "                           if m in str_column]].drop_duplicates()\n",
    "\n",
    "# We are not dropping duplicates for the combined data containing ApplicationId\n",
    "\n",
    "llm_candidate_data_bert = fdata[[\"ApplicationId\"] + \n",
    "                                [m + \"__bertpp\" \n",
    "                                 for m in can_column \n",
    "                                 if m in str_column]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b.2.3 Data featurization"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/notebooks/03_featurization/3b_featurization.ipynb
   "execution_count": 7,
=======

   "execution_count": 15,

>>>>>>> 20ba1f8c5294aff0874b91a3115424430b0b645b:notebooks/3b_featurization.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading BERT model and tokenizer\n",
    "# Shifting to GPU for faster calculations\n",
    "\n",
    "device = (\n",
    "    torch.device(\"mps\") \n",
    "    if torch.backends.mps.is_available() \n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Moving model to GPU\n",
    "model = AutoModel.from_pretrained(model_name).to(device)  "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:src/notebooks/03_featurization/3b_featurization.ipynb
   "execution_count": 8,
=======

   "execution_count": 16,

>>>>>>> 20ba1f8c5294aff0874b91a3115424430b0b645b:notebooks/3b_featurization.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:src/notebooks/03_featurization/3b_featurization.ipynb
      "Processing rows: 100%|██████████| 8473/8473 [1:12:34<00:00,  1.95it/s]  \n"
=======

      "Processing rows: 100%|██████████| 8473/8473 [1:13:35<00:00,  1.92it/s]  \n"

>>>>>>> 20ba1f8c5294aff0874b91a3115424430b0b645b:notebooks/3b_featurization.ipynb
     ]
    }
   ],
   "source": [
    "# Gathering and applying BERT base embedded vector for opportunity columns\n",
    "\n",
    "job_opportunityid_bert_dict_hstack = {}\n",
    "job_opportunityid_bert_dict_vstack = {}\n",
    "\n",
    "for index, row in tqdm(\n",
    "    llm_job_data_bert[\n",
    "        [m + \"__bertpp\" for m in job_column if m in str_column]\n",
    "    ].iterrows(), \n",
    "        desc = \"Processing rows\", \n",
    "        total = len(llm_job_data_bert)\n",
    "    ):\n",
    "    \n",
    "    embeddings_values = []\n",
    "    \n",
    "    for column in [m for m in job_column if m in str_column]:\n",
    "        text = llm_job_data_bert.at[index, column + \"__bertpp\"]\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        input = tokenizer(\n",
    "            sentences, padding = True, \n",
    "            truncation = True, \n",
    "            return_tensors = \"pt\"\n",
    "        ).to(device) \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(**input)\n",
    "        embeddings_values.append(\n",
    "            np.mean(\n",
    "                output.last_hidden_state.mean(dim=1).cpu().numpy(), axis = 0))\n",
    "            \n",
    "    vector_h = np.hstack(tuple(embeddings_values))\n",
    "    vector_v = np.mean((tuple(embeddings_values)), axis = 0)\n",
    "\n",
    "    job_opportunityid_bert_dict_hstack[\n",
    "        llm_job_data_bert.at[index, \"OpportunityId\"]\n",
    "    ] = vector_h\n",
    "\n",
    "    job_opportunityid_bert_dict_vstack[\n",
    "        llm_job_data_bert.at[index, \"OpportunityId\"]\n",
    "    ] = vector_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,) (768,)\n"
     ]
    }
   ],
   "source": [
    "#Checking the shape of a random vector that are nested inside dictionaries\n",
    "print(\n",
    "    job_opportunityid_bert_dict_hstack['MbzeABKVn06G8irkoHJeIg=='].shape, \n",
    "    job_opportunityid_bert_dict_vstack['MbzeABKVn06G8irkoHJeIg=='].shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 110267/110267 [9:56:41<00:00,  3.08it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Gathering and applying BERT base embedded vector for candidate columns\n",
    "\n",
    "can_applicationid_bert_dict_hstack = {}\n",
    "can_applicationid_bert_dict_vstack = {}\n",
    "\n",
    "for index, row in tqdm(\n",
    "    llm_candidate_data_bert[\n",
    "        [m + \"__bertpp\" for m in can_column if m in str_column]\n",
    "    ].iterrows(), \n",
    "        desc = \"Processing rows\", \n",
    "        total = len(llm_candidate_data_bert)\n",
    "    ):\n",
    "    \n",
    "    embeddings_values = []\n",
    "    \n",
    "    for column in [m for m in can_column if m in str_column]:\n",
    "        text = llm_candidate_data_bert.at[index, column + \"__bertpp\"]\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        input = tokenizer(\n",
    "            sentences, padding = True, \n",
    "            truncation = True, \n",
    "            return_tensors = \"pt\"\n",
    "        ).to(device) \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(**input)\n",
    "        embeddings_values.append(\n",
    "            np.mean(\n",
    "                output.last_hidden_state.mean(dim=1).cpu().numpy(), axis = 0))\n",
    "            \n",
    "    vector_h = np.hstack(tuple(embeddings_values))\n",
    "    vector_v = np.mean(tuple(embeddings_values), axis = 0)\n",
    "    \n",
    "    can_applicationid_bert_dict_hstack[\n",
    "        llm_candidate_data_bert.at[index, \"ApplicationId\"]\n",
    "    ] = vector_h\n",
    "\n",
    "    can_applicationid_bert_dict_vstack[\n",
    "        llm_candidate_data_bert.at[index, \"ApplicationId\"]\n",
    "    ] =vector_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10752,) (3072,)\n",
      "(768,) (768,)\n"
     ]
    }
   ],
   "source": [
    "# Printing a random rows to see the shape of the dictionararies generated\n",
    "\n",
    "print(\n",
    "    can_applicationid_bert_dict_hstack['nTzdqGj020CYqTouPocGSg=='].shape, \n",
    "    job_opportunityid_bert_dict_hstack['MbzeABKVn06G8irkoHJeIg=='].shape\n",
    ")\n",
    "\n",
    "print(\n",
    "    can_applicationid_bert_dict_vstack['nTzdqGj020CYqTouPocGSg=='].shape, \n",
    "    job_opportunityid_bert_dict_vstack['MbzeABKVn06G8irkoHJeIg=='].shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying vectors to the data \n",
    "\n",
    "for column_name in fdata[uid_column]:\n",
    "    if column_name == \"ApplicationId\":\n",
    "        fdata[\"opportunity__bert_hstack\"] = fdata[\"ApplicationId\"].apply(\n",
    "            lambda x : can_applicationid_bert_dict_hstack[x]\n",
    "        )\n",
    "        \n",
    "    if column_name == \"OpportunityId\":\n",
    "        fdata[\"candidate__bert_hstack\"] = fdata[\"OpportunityId\"].apply(\n",
    "            lambda x : job_opportunityid_bert_dict_hstack[x]\n",
    "        )\n",
    "\n",
    "for column_name in fdata[uid_column]:\n",
    "    if column_name == \"ApplicationId\":\n",
    "        fdata[\"opportunity__bert_vstack\"] = fdata[\"ApplicationId\"].apply(\n",
    "            lambda x : can_applicationid_bert_dict_vstack[x]\n",
    "        )\n",
    "        \n",
    "    if column_name == \"OpportunityId\":\n",
    "        fdata[\"candidate__bert_vstack\"] = fdata[\"OpportunityId\"].apply(\n",
    "            lambda x : job_opportunityid_bert_dict_vstack[x]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,) (768,) (3072,) (3072,)\n"
     ]
    }
   ],
   "source": [
    "fdata[\n",
    "    [\"opportunity__bert_vstack\", \"candidate__bert_vstack\",\n",
    "     \"opportunity__bert_hstack\", \"candidate__bert_hstack\"]\n",
    "  ]\n",
    "\n",
    "print(\n",
    "    fdata['opportunity__bert_vstack'][1].shape,\n",
    "    fdata['candidate__bert_vstack'][1].shape, \n",
    "    fdata['candidate__bert_hstack'][1].shape, \n",
    "    fdata['candidate__bert_hstack'][1].shape\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b.3 Saving data for futher analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting rdata to a pickle file\n",
    "\n",
    "\"\"\" \n",
    "Creating featurizeddata_w2v that caries all the applicant, opportunity \n",
    "related vectors\n",
    "\"\"\"\n",
    "\n",
    "fdata[\n",
    "    [\n",
    "        \"opportunity__bert_vstack\", \"candidate__bert_vstack\", \n",
    "        \"opportunity__bert_hstack\", \"candidate__bert_hstack\"\n",
    "      ]\n",
    "    ].to_pickle(\n",
    "        dataloc + \"/interim/featurizeddata_bert.pkl\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dictionaries into the variables for pickle\n",
    "\n",
    "# Creating dictionary\n",
    "bert_dict = {}\n",
    "\n",
    "# Adding dictionaries\n",
    "bert_dict[\n",
    "    'job_opportunityid_bert_dict_hstack'\n",
    "    ] = job_opportunityid_bert_dict_hstack\n",
    "bert_dict[\n",
    "    'can_application_bert_dict_hstack'\n",
    "    ] = can_applicationid_bert_dict_hstack\n",
    "\n",
    "bert_dict[\n",
    "    'job_opportunityid_bert_dict_vstack'\n",
    "    ] = job_opportunityid_bert_dict_vstack\n",
    "bert_dict[\n",
    "    'can_application_bert_dict_vstack'\n",
    "    ] = can_applicationid_bert_dict_vstack\n",
    "\n",
    "# Saving variables dictionary\n",
    "with open(dataloc + '/interim/bert_data_dictionary.pkl', 'wb') as file:\n",
    "    pickle.dump(bert_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

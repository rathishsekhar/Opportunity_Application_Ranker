# Opportunity_Application_Ranker - under construction
The project  involve analyzing textual data from job postings (opportunities) and applicant profiles to calculate similarity and rank applicants based on their similarity to a given job opportunity. Further an application would be created to demonstrate the project.

# Table of Contents
1. Project Overview
2. Motivation
3. Project Structure
4. Data 
5. Features
6. Prerequisites
7. Setup
8. Usage
9. Results
10. Limitations
11. Ethical Considerations
12. Contributing
13. License
14. Acknowledgements

# Project Overview
This project analyzes candidate data recorded by executive recruiters or headhunters. The projects aims to analyze typical job-candidate data to 
1. Identify suitable job matches for each candidate within the existing database of jobs
2. Calculates the compatibility between candidates versus the associated jobs through machine learning techniques. 
3. Create and demonstrate an application which could be used to input new candidates profile and receive the job that matches closest to the candidates profile. 

Overall, the project aims to help recruiters efficiently align candidate profiles with relevant job opportunities. The insights generated by this project aim to streamline the matching process, reducing the manual effort required to match candidates to job roles. This approach could be extended to other applications, such as matching donors to applicants, mentors to mentees, or students to programs.

# Motivation
Matching assessed candidates with existing job profiles is a laborious process, especially when dealing with large volumes of constantly updated information on both candidates and jobs. Executive recruiters are required to spend significant hours manually evaluating matches. Without technological support, many recruitment firms may overlook ideal candidates, leading to missed hiring opportunities and reduced revenue.

This project aims to add an automated filtering layer using machine learning techniques, enabling recruiters to identify the top matches for candidates efficiently. With this model, recruiters can focus on the most relevant candidates and jobs, ultimately improving the match quality and reducing manual work. A successful model would decrease the number of hours spent on matching, improve match rates, and potentially support a wide range of additional recruitment use cases.

Furthermore, this project explores advanced NLP techniques, employing transformer-based encoding to process and interpret complex candidate and job data and as such has helped the author gain deeper understanding in NLP techniques. Through a comparative analysis of various models, this project demonstrates effective methods for evaluating and optimizing model performance for recruitment applications. 

# Project structure
├── inputs/                     # Raw and processed data files that would be inputted into the model
├── notebooks/                  # Model wise Jupyter notebooks for exploratory analysis, preprocessing, featurization and, model training and evaluation
├── outputs/                    # Model wise Processed data model for further use in developing an app and visualizations comparing the models
├── src/                        # Source code files
│   ├── getter/                 # Scripts for fetching data
│   ├── preprocessing/          # Scripts for enabling preprocessing 
│   ├── featurization/          # Featurization scripts
│   └── model training/         # Model training scripts
├── configuration               # Configuration file
├── requirements.txt            # Python dependencies
├── README.md                   # Project overview (this file)
└── streamlit_app_all_models    # Streamlit based application code for all models

# Data
### Data source
The data was 

### Description
The original raw file contained as single large dataset comprising of 24 colums and just over 110000 rows. The data is a combination of both job information and the candidate inforamton. From the look at it, it looks like a data that was created by the recruiters or by someone who has evaluated teh candidate at a certain level of interviewing stage. Each of the row implies a candidate associated witha particular job description. This means that we have a database of candidates applying for the particular role. Therefore establishing one to many relation between the job and candidate datasets. Having observed the data types for various columns, it is evident that the data has been obtained from the database collected through an application. 

The dataset consisted variety of datatypes for example: string, number, json objects. 

#### Job features
OpportunityId (class 'str') - Unique id for the job in the database
ExternalBriefDescription (class 'str') - Brief description of the job posting
ExternalDescription (class 'str') - Full description of the job posting
Title (class 'str') - Job posting's name
JobCategoryName (class 'str') - Predefined class to which the job posting belongs

#### Candidate features
- ApplicationId (class 'str') - Unique id for the applicant
- IsRejected (class 'numpy.bool') - Boolean value provided if the client was rejected in previous round
- IsCandidateInternal (class 'numpy.bool') - Boolean value refering if the candidate was refereed internally
- BehaviorCriteria (class 'numpy.ndarray') - Candidate's behaviour as per the criterion evaluated by the evaluator
- MotivationCriteria (class 'numpy.ndarray) - Candidate's motivation as per the criterion evaluated by the evaluator
- EducationCriteria (class 'numpy.ndarray') - Educational aspects of the candidate as per the criterion evaluated by an evaluator
- LicenseAndCertificationCriteria (class 'numpy.ndarray') - Licences and certifications aspects of the candidate as per the criterion evaluated by an evaluator
- SkillCriteria (class 'numpy.ndarray') - Skill sets as per the criterion evaluated by an evaluator
- WorkExperiences (class 'numpy.ndarray) - Details of the candidate's work experience
- Educations (class 'numpy.ndarray') - Details of the candidate's education
- LicenseAndCertifications (class 'numpy.ndarray') - Details associated with the candidate's licences and certifications
- Skills (class 'numpy.ndarray') - List of all relevant skills 
- Motivations (class 'numpy.ndarray') - Motivation criterion as listed by the candidate
- Behaviors (class 'numpy.ndarray) - Behavioural aspects listed by the candidate
- StepId (class 'str') - Unique id for the next step taken by the evaluator
- StepName (class 'str') - Details of the next step taken by the evaluator
- Tag (class 'numpy.float64') - Unknown number associated in the data base
- StepGroup (class 'str') - Category which the next step taken by the evaluator falls under
- pass_first_step (class 'numpy.bool') - Boolean informing if the data passed through the next step

### Data Preprocessing
The data used was preprocessed to cater to the input requirements of the various models viz. TF-IDF weighted word2vec, BERT based 

Outline any data-cleaning steps taken, such as handling missing values or feature engineering. 

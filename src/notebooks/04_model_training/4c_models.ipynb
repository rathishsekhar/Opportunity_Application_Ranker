{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4c. Models - distill BERT\n",
    "\n",
    "Description of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c.0 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c.1 Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to project directory\n",
    "\n",
    "os.chdir(Path(os.path.realpath(\"\")).resolve().parents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules that fetch the data\n",
    "\n",
    "from src.getter.load_application_and_opportunity import get_interim_data\n",
    "\n",
    "# Gathering the data\n",
    "\n",
    "featurizeddata_dbert = get_interim_data(\"featurizeddata_dbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of column names that contains the names of the columns, if they belong to the job or candidate\n",
    "\n",
    "job_column = ['ExternalBriefDescription','ExternalDescription', 'Title', \n",
    "              'JobCategoryName']\n",
    "uid_column = ['OpportunityId', 'ApplicationId']\n",
    "can_column = [\n",
    "    'IsCandidateInternal',\n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria',\n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepName', \n",
    "    'StepGroup',\n",
    "    'pass_first_step'\n",
    "] # Column - 'Tag' Will be added later, StepId has been removed\n",
    "sel_column = ['IsRejected']\n",
    "\n",
    "# Defining list of columns based on the type of contents\n",
    "\n",
    "str_column = [\n",
    "    'ExternalBriefDescription', \n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName', \n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria', \n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepId', \n",
    "    'StepName', \n",
    "    'StepGroup'\n",
    "]\n",
    "bool_column = ['IsCandidateInternal', 'pass_first_step']\n",
    "float_column = ['Tag']\n",
    "\n",
    "# Defining list of columns based on the models\n",
    "\n",
    "model_names = [\"w2v\", \"bert\", \"dbert\"]\n",
    "\n",
    "# Setting the local folder location\n",
    "dataloc = '/Users/rathish/Documents/Projects/Opportunity_Application_Ranker/inputs/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering necessary arrays and applying Standard Scaller\n",
    "\n",
    "standardscaler = StandardScaler(copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top n-similar cosine vectors\n",
    "def n_pairwise_cosine_similar(matrix_1, matrix_2, n = 3):\n",
    "\n",
    "    '''\n",
    "    Returns diagonal values of cosine similarity and list of index containing \n",
    "    that top n similar cosine\n",
    "\n",
    "    Args:\n",
    "        matrix_1 (numpy array: 2D): Array containing vectors whose similarity \n",
    "        is to be checked\n",
    "        matrix_2 (numpy array: 2D): Array with which the similarity is to be \n",
    "        compared to\n",
    "        \n",
    "    n (int, default: 3): number of top similar values to be found\n",
    "\n",
    "    Returns:\n",
    "    diag_cosine_similarity (numpy array): Direct cosine similarity between \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    matrix_1 = (matrix_1/np.linalg.norm(matrix_1, axis = 1)[:, np.newaxis])\n",
    "    matrix_2 = (matrix_2/np.linalg.norm(matrix_2, axis = 1)[:, np.newaxis])\n",
    "\n",
    "    # Moving matrices to GPU\n",
    "    device = torch.device(\n",
    "        \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "        )\n",
    "    \n",
    "    similarity_dict = {}\n",
    "    cosine_similarity = {}\n",
    "\n",
    "    for index_1, values_1 in tqdm(\n",
    "        enumerate(matrix_1), desc = \"Processing\", total = len(matrix_1)\n",
    "    ):\n",
    "        temp = {}\n",
    "    \n",
    "        for index_2, values_2 in enumerate(matrix_2):\n",
    "            temp_value = np.dot(values_1, values_2)\n",
    "\n",
    "            if index_1 == index_2:\n",
    "                cosine_similarity[index_1] = temp_value\n",
    "                \n",
    "            temp[index_2] = temp_value\n",
    "\n",
    "        sorteddict = sorted(\n",
    "            temp.items(), \n",
    "            key = lambda x: x[1], \n",
    "            reverse = True\n",
    "        )[:n]\n",
    "        \n",
    "        similarity_dict[index_1] = sorteddict #.keys() if keys are wanted\n",
    "    \n",
    "    return cosine_similarity, similarity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c.2.1 Working on distill-BERT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['opportunity__dbert_hstack', 'candidate__dbert_hstack',\n",
       "       'opportunity__dbert_vstack', 'candidate__dbert_vstack'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking columns\n",
    "\n",
    "featurizeddata_dbert.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving arrays for dbert vectors - horizontally stacked vectors\n",
    "\n",
    "opportunity__dbert_hstack = np.array(\n",
    "    [np.array(x) for x in featurizeddata_dbert['opportunity__dbert_hstack']]\n",
    ")\n",
    "# standardscaler.fit_transform(opportunity__dbert)\n",
    "\n",
    "candidate__dbert_hstack = np.array(\n",
    "    [np.array(x) for x in featurizeddata_dbert['candidate__dbert_hstack']]\n",
    ")\n",
    "# standardscaler.fit_transform(candidate__dbert)\n",
    "\n",
    "\n",
    "# Deriving arrays for dbert vectors - vertically stacked vectors\n",
    "\n",
    "opportunity__dbert_vstack = np.array(\n",
    "    [np.array(x) for x in featurizeddata_dbert['opportunity__dbert_vstack']]\n",
    ")\n",
    "candidate__dbert_vstack = np.array(\n",
    "    [np.array(x) for x in featurizeddata_dbert['candidate__dbert_vstack']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the dimensionality of the dbert vectors through PCA\n",
    "\n",
    "no_of_dimensions = min(\n",
    "    candidate__dbert_hstack.shape[1], opportunity__dbert_hstack.shape[1]\n",
    ")\n",
    "pca = PCA(n_components = no_of_dimensions, copy = False)\n",
    "\n",
    "if candidate__dbert_hstack.shape[1] >= opportunity__dbert_hstack.shape[1]:\n",
    "    candidate__dbert_hstack = pca.fit_transform(candidate__dbert_hstack)\n",
    "else:\n",
    "    opportunity__dbert_hstack = pca.fit_transform(opportunity__dbert_hstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110267, 3072) (110267, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Checking the dimension after PCA\n",
    "print(candidate__dbert_hstack.shape, opportunity__dbert_hstack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 110267/110267 [3:44:16<00:00,  8.19it/s] \n"
     ]
    }
   ],
   "source": [
    "# Running the n_pairwise_cosine_similar for horizontally stacked vectors\n",
    "\n",
    "(\n",
    "    cosine_similarity__dbert_hstack, similarity_dict__dbert_hstack\n",
    ") = n_pairwise_cosine_similar(\n",
    "    opportunity__dbert_hstack, candidate__dbert_hstack, n= 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 110267/110267 [3:11:41<00:00,  9.59it/s] \n"
     ]
    }
   ],
   "source": [
    "# Running the n_pairwise_cosine_similar for vertically stacked vectors\n",
    "\n",
    "(\n",
    "    cosine_similarity__dbert_vstack, similarity_dict__dbert_vstack\n",
    ") = n_pairwise_cosine_similar(\n",
    "    opportunity__dbert_vstack, candidate__dbert_vstack, n= 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c.2.1 Saving the similarity data - distillBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dictionaries into the variables for pickle\n",
    "similarity_dbert = {}\n",
    "\n",
    "# Adding dictionaries\n",
    "similarity_dbert[\n",
    "    \"cosine_similarity__dbert_hstack\"\n",
    "] = cosine_similarity__dbert_hstack\n",
    "similarity_dbert[\n",
    "    \"similarity_dict__dbert_hstack\"\n",
    "] = similarity_dict__dbert_hstack\n",
    "\n",
    "similarity_dbert[\n",
    "    \"cosine_similarity__dbert_vstack\"\n",
    "] = cosine_similarity__dbert_vstack\n",
    "similarity_dbert[\n",
    "    \"similarity_dict__dbert_vstack\"\n",
    "] = similarity_dict__dbert_vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data - Gathering necessary libraries\n",
    "\n",
    "from src.getter.save_application_and_opportunity import save_processed_data\n",
    "\n",
    "# Saving the data \n",
    "save_processed_data(similarity_dbert, \"similarity_dict_dbert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

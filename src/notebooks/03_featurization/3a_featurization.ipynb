{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a. Featurizing the data - Word 2 Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.1.1 Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpportunityId</th>\n",
       "      <th>ApplicationId</th>\n",
       "      <th>ExternalBriefDescription</th>\n",
       "      <th>ExternalDescription</th>\n",
       "      <th>Title</th>\n",
       "      <th>JobCategoryName</th>\n",
       "      <th>IsRejected</th>\n",
       "      <th>IsCandidateInternal</th>\n",
       "      <th>BehaviorCriteria</th>\n",
       "      <th>MotivationCriteria</th>\n",
       "      <th>...</th>\n",
       "      <th>SkillCriteria__mbertpp</th>\n",
       "      <th>WorkExperiences__mbertpp</th>\n",
       "      <th>Educations__mbertpp</th>\n",
       "      <th>LicenseAndCertifications__mbertpp</th>\n",
       "      <th>Skills__mbertpp</th>\n",
       "      <th>Motivations__mbertpp</th>\n",
       "      <th>Behaviors__mbertpp</th>\n",
       "      <th>StepId__mbertpp</th>\n",
       "      <th>StepName__mbertpp</th>\n",
       "      <th>StepGroup__mbertpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MbzeABKVn06G8irkoHJeIg==</td>\n",
       "      <td>nTzdqGj020CYqTouPocGSg==</td>\n",
       "      <td>$16.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$16.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Call Cente...</td>\n",
       "      <td>Degree Some college Description None Graduatio...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 4 ScaleValueName Advanced Skill Clo...</td>\n",
       "      <td>Description Inspired to perform well by moneta...</td>\n",
       "      <td>Description Devoted to a task or purpose with ...</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7SPt0A57/kyzM9hE9vxDRg==</td>\n",
       "      <td>QVk5MFCZ70WvlZE9FzAW9g==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Coordinato...</td>\n",
       "      <td>Degree Diploma Description None GraduationMont...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Sales</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7SPt0A57/kyzM9hE9vxDRg==</td>\n",
       "      <td>I1kcPlAw3E+rqceh0qrutQ==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Direct Car...</td>\n",
       "      <td>Degree HIGH SCHOOL DIPLOMA Description None Gr...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 4 ScaleValueName Advanced Skill Cash</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zolSWBFjWESbfkj8AXLYwA==</td>\n",
       "      <td>VTCXZK6/ZUWJDpxTcm2CRg==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear 2019.0 JobTitle Package ...</td>\n",
       "      <td>Degree Associate in Early Description None Gra...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Cashier</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zolSWBFjWESbfkj8AXLYwA==</td>\n",
       "      <td>I6KgcL0jdkG8wBnL1+BZ/g==</td>\n",
       "      <td>$15.00 Per Hour\\n\\nAt Orkin, our purpose is to...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;$15.00 Per Hour&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;s...</td>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'Description': 'Capable of carrying out a gi...</td>\n",
       "      <td>[{'Description': 'Inspired to perform well by ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MinimumScaleValue 3 MinimumScaleValueName Inte...</td>\n",
       "      <td>EndMonth None EndYear None JobTitle Warehouse ...</td>\n",
       "      <td>Degree Bachelor of Business Admin Description ...</td>\n",
       "      <td>None</td>\n",
       "      <td>ScaleValue 5 ScaleValueName Expert Skill Forklift</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K8yQlic+/UiXxBMpOnAoLQ==</td>\n",
       "      <td>Decline</td>\n",
       "      <td>declined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              OpportunityId             ApplicationId  \\\n",
       "0  MbzeABKVn06G8irkoHJeIg==  nTzdqGj020CYqTouPocGSg==   \n",
       "1  7SPt0A57/kyzM9hE9vxDRg==  QVk5MFCZ70WvlZE9FzAW9g==   \n",
       "2  7SPt0A57/kyzM9hE9vxDRg==  I1kcPlAw3E+rqceh0qrutQ==   \n",
       "3  zolSWBFjWESbfkj8AXLYwA==  VTCXZK6/ZUWJDpxTcm2CRg==   \n",
       "4  zolSWBFjWESbfkj8AXLYwA==  I6KgcL0jdkG8wBnL1+BZ/g==   \n",
       "\n",
       "                            ExternalBriefDescription  \\\n",
       "0  $16.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "1  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "2  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "3  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "4  $15.00 Per Hour\\n\\nAt Orkin, our purpose is to...   \n",
       "\n",
       "                                 ExternalDescription  \\\n",
       "0  <p><strong>$16.00 Per Hour</strong></p>\\n<p><s...   \n",
       "1  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "2  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "3  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "4  <p><strong>$15.00 Per Hour</strong></p>\\n<p><s...   \n",
       "\n",
       "                         Title   JobCategoryName  IsRejected  \\\n",
       "0  Customer Service Specialist  Customer Service        True   \n",
       "1  Customer Service Specialist  Customer Service        True   \n",
       "2  Customer Service Specialist  Customer Service        True   \n",
       "3  Customer Service Specialist  Customer Service        True   \n",
       "4  Customer Service Specialist  Customer Service        True   \n",
       "\n",
       "   IsCandidateInternal                                   BehaviorCriteria  \\\n",
       "0                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "1                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "2                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "3                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "4                False  [{'Description': 'Capable of carrying out a gi...   \n",
       "\n",
       "                                  MotivationCriteria  ...  \\\n",
       "0  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "1  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "2  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "3  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "4  [{'Description': 'Inspired to perform well by ...  ...   \n",
       "\n",
       "                              SkillCriteria__mbertpp  \\\n",
       "0  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "1  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "2  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "3  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "4  MinimumScaleValue 3 MinimumScaleValueName Inte...   \n",
       "\n",
       "                            WorkExperiences__mbertpp  \\\n",
       "0  EndMonth None EndYear None JobTitle Call Cente...   \n",
       "1  EndMonth None EndYear None JobTitle Coordinato...   \n",
       "2  EndMonth None EndYear None JobTitle Direct Car...   \n",
       "3  EndMonth None EndYear 2019.0 JobTitle Package ...   \n",
       "4  EndMonth None EndYear None JobTitle Warehouse ...   \n",
       "\n",
       "                                 Educations__mbertpp  \\\n",
       "0  Degree Some college Description None Graduatio...   \n",
       "1  Degree Diploma Description None GraduationMont...   \n",
       "2  Degree HIGH SCHOOL DIPLOMA Description None Gr...   \n",
       "3  Degree Associate in Early Description None Gra...   \n",
       "4  Degree Bachelor of Business Admin Description ...   \n",
       "\n",
       "  LicenseAndCertifications__mbertpp  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                              None   \n",
       "4                              None   \n",
       "\n",
       "                                     Skills__mbertpp  \\\n",
       "0  ScaleValue 4 ScaleValueName Advanced Skill Clo...   \n",
       "1     ScaleValue 5 ScaleValueName Expert Skill Sales   \n",
       "2    ScaleValue 4 ScaleValueName Advanced Skill Cash   \n",
       "3   ScaleValue 5 ScaleValueName Expert Skill Cashier   \n",
       "4  ScaleValue 5 ScaleValueName Expert Skill Forklift   \n",
       "\n",
       "                                Motivations__mbertpp  \\\n",
       "0  Description Inspired to perform well by moneta...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                  Behaviors__mbertpp  \\\n",
       "0  Description Devoted to a task or purpose with ...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "            StepId__mbertpp StepName__mbertpp StepGroup__mbertpp  \n",
       "0  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "1  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "2  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "3  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "4  K8yQlic+/UiXxBMpOnAoLQ==           Decline           declined  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloc ='/Users/rathish/Documents/Projects/Opportunity_Application_Ranker/inputs/data'\n",
    "fdata = pd.read_pickle(dataloc + '/interim/preprocesseddata.pkl')\n",
    "fdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.1.2 Defining column names for featurization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list containing names of the columns\n",
    "\n",
    "job_column = [\n",
    "    'ExternalBriefDescription',\n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName'\n",
    "]\n",
    "\n",
    "uid_column = ['OpportunityId', 'ApplicationId']\n",
    "\n",
    "# Column - 'Tag' Will be added later\n",
    "can_column = [\n",
    "    'IsCandidateInternal',\n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria',\n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepId', \n",
    "    'StepName', \n",
    "    'StepGroup',\n",
    "    'pass_first_step'\n",
    "] \n",
    "\n",
    "sel_column = ['IsRejected']\n",
    "\n",
    "# Defining list of columns based on the type of contents\n",
    "\n",
    "str_column = [\n",
    "    'ExternalBriefDescription', \n",
    "    'ExternalDescription', \n",
    "    'Title', \n",
    "    'JobCategoryName', \n",
    "    'BehaviorCriteria', \n",
    "    'MotivationCriteria', \n",
    "    'EducationCriteria', \n",
    "    'LicenseAndCertificationCriteria', \n",
    "    'SkillCriteria', \n",
    "    'WorkExperiences', \n",
    "    'Educations', \n",
    "    'LicenseAndCertifications', \n",
    "    'Skills', \n",
    "    'Motivations', \n",
    "    'Behaviors', \n",
    "    'StepId', \n",
    "    'StepName', \n",
    "    'StepGroup'\n",
    "]\n",
    "\n",
    "bool_column = ['IsCandidateInternal', 'pass_first_step']\n",
    "\n",
    "float_column = ['Tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.2 TFIDF weighted word2vec vectorization\n",
    "\n",
    "Let's use TFIDF weighted word2vec for generating the necessary features to measure similarity. \n",
    "To do this, let's generate two functions - tfidf_weighted_word2vec, which inputs the column name and the data to generate the TFIDF vocabulary, TFIDF's - idf values, and word2vec vocab:vector after training the data. \n",
    "The second function i.e. TFIDF w2v_vectorizer intakes all of the variables generated in the first function along and applies it to a particular text to achieve TFIDF weighted word to vec. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.2.1 Creating functions that derive TFIDF weighted word2vec information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the TF-IDF vector dimension to other comparitive models - in this case 512\n",
    "vector_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_weighted_word2vec(data, colname):\n",
    "    \"\"\"\n",
    "    Function generates necessary components to derive TF-IDF weighted Word2Vec\n",
    "    from an entire data column.    \n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): Dataset containing columns text for converting \n",
    "        into word2vec\n",
    "    \n",
    "        col_names (str) : Name of the target column on which the operation \n",
    "        needs to be performed\n",
    "\n",
    "    Returns: \n",
    "        w2v (dict) : Dictionary with keys as words and values as i.e. word2vec \n",
    "        model generated respective vectors\n",
    "        word2weight (dict) : Dictionary with words and their corresponding \n",
    "        TF-IDF weights \n",
    "        vocab(dict) : Vocabulary dictionary with word indices\n",
    "    \"\"\"\n",
    "\n",
    "    # Generating coldata\n",
    "    c = data[colname].tolist()\n",
    "    c = [str(x) for x in c]\n",
    "    coldata = []\n",
    "    \n",
    "    # Creating model and tokenizing words for the moedl\n",
    "    model = Word2Vec(window = 2, min_count = 3, sg = 1, vector_size = vector_dim)\n",
    "    \n",
    "    for x in c:\n",
    "        coldata.append(gensim.utils.simple_preprocess(x))\n",
    "\n",
    "    # Creating model vocabulary from the tokens and then training and \n",
    "    # later bundling into a dictionary\n",
    "    \n",
    "    model.build_vocab(coldata)\n",
    "    model.train(corpus_iterable=coldata, total_examples= model.corpus_count, \n",
    "                epochs=model.epochs)\n",
    "    \n",
    "    w2v = dict(zip(model.wv.index_to_key, model.wv.vectors.round(3)))\n",
    "    \n",
    "    # Creating TFIDF vectorizer model\n",
    "    \n",
    "    tfidfvectorizer = TfidfVectorizer()\n",
    "    tfidfvectorizer.fit_transform(c)\n",
    "    vocab = tfidfvectorizer.vocabulary_.items()\n",
    "\n",
    "    # Generating word2weight dictionary of word and its TFIDF values\n",
    "    word2weight = [(w, round(tfidfvectorizer.idf_[i], 3)) \n",
    "                   for w, i in tfidfvectorizer.vocabulary_.items()]\n",
    "    word2weight  = dict(word2weight)\n",
    "\n",
    "    return w2v, word2weight, vocab\n",
    "\n",
    "\n",
    "def tfidfw2v_vectorizer(text, w2v, word2weight):\n",
    "    \"\"\"\n",
    "\n",
    "    Perform TF-IDF weighted Word2Vec embdedding on a tet column in a DataFrame\n",
    "\n",
    "    Function calculates the TFIDF (from scikit-learn's TFIDFfVectorizer) \n",
    "    weighted word2vec (from gensim.Word2Vec) as per the following formulae:\n",
    "    Tfidf w2v (w1,w2..) = \n",
    "    (tfidf(w1) * w2v(w1) + tfidf(w2) * w2v(w2) + â€¦)/(tfidf(w1) + tfidf(w2) + â€¦\n",
    "    from various inputs. \n",
    "\n",
    "    Args:\n",
    "        text (str): Input text for which to calculate the TF-IDF weighted \n",
    "        Word2Vec vector.\n",
    "        w2v (dict): Dictionary with keys as words and values as their \n",
    "        respective vectors.\n",
    "        word2weight (dict): Dictionary with words and their corresponding\n",
    "        TF-IDF  weights.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: TF-IDF weighted Word2Vec vector for the input text.\n",
    "\n",
    "    \"\"\"\n",
    "    words = text.split() \n",
    "\n",
    "    if len(words) == 0:\n",
    "        \n",
    "        return np.zeros(vector_dim) # BERT and dBERT create 512 dimensional vectors\n",
    "\n",
    "    else:\n",
    "        numerator_vector = np.zeros(vector_dim)\n",
    "        denominator_value = 0.0\n",
    "        \n",
    "        for word in words:\n",
    "            \n",
    "            if word in w2v.keys() and word in word2weight.keys():\n",
    "                \n",
    "                numerator_val = words.count(word)*word2weight[word]*w2v[word]\n",
    "                numerator_vector += numerator_val\n",
    "               \n",
    "                denominator_val = words.count(word)*word2weight[word]\n",
    "                denominator_value += denominator_val\n",
    "        \n",
    "        if denominator_value == 0.0:\n",
    "            \n",
    "            return np.zeros(vector_dim)\n",
    "       \n",
    "        else: \n",
    "            \n",
    "            return np.round(numerator_vector/denominator_value, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.2.2 Applying the TFIDF weighted word2vec function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the TFIDF - avg word 2 vec\n",
    "\n",
    "for colname in str_column:\n",
    "    w2v, word2weight, vocab = tfidf_weighted_word2vec(\n",
    "        fdata, colname + \"__w2vpp\"\n",
    "    )\n",
    "    \n",
    "    fdata[colname + \"__w2v\"] = fdata[colname + \"__w2vpp\"].apply(\n",
    "        lambda x: tfidfw2v_vectorizer(x, w2v,word2weight)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.2.3 Handling boolean float columns with one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Applying OneHotEncoder and generating a vector that is padded with zeros to \n",
    "attain length = vector_dim, for easy vertical stacking\n",
    "\"\"\"\n",
    "\n",
    "onehotencoder = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')\n",
    "\n",
    "for colname in bool_column:\n",
    "    fdata[colname + \"__w2v\"] = [np.pad(\n",
    "        x, \n",
    "        (0, vector_dim - (len(x) % vector_dim)), \n",
    "        'constant'\n",
    "    ) for x in onehotencoder.fit_transform(\n",
    "        np.reshape(np.array(fdata[colname]), (-1, 1))\n",
    "    )]\n",
    "\n",
    "\"\"\"\n",
    "minmaxscaler = MinMaxScaler() isn't being applied as float data contained\n",
    "None objects. The None objects were converted to -1. Applying minmax scaller \n",
    "would modify the data\n",
    "\"\"\"\n",
    "\n",
    "for colname in float_column:\n",
    "    fdata[colname + \"__w2v\"] = [np.pad(\n",
    "        x, \n",
    "        (0,vector_dim - (len(x)%vector_dim)), \n",
    "        'constant'\n",
    "    ) for x in (np.reshape(\n",
    "        np.array(fdata['Tag']), (-1, 1)\n",
    "    )\n",
    "    )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.2.4 Stacking all the vectors together\n",
    "\n",
    "The stacking of vectors could be done in two ways either horizontally or vertically. \n",
    "Horizontal stacking is simple concatenation giving rise to vectors or varied lengths. \n",
    "In vertical stacking, we take the mean vector values stacked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding relevant arrays column wise to create larger vectors\n",
    "\n",
    "def hstacker(row_arrays):\n",
    "    \"\"\"\n",
    "    Function that concatenates each of the column data for each row\n",
    "    \"\"\"\n",
    "    return np.concatenate(row_arrays)\n",
    "\n",
    "def vstacker(row_arrays):\n",
    "    \"\"\"\n",
    "    Gives the mean vector for the vectors in columns row-wise\n",
    "    \"\"\"\n",
    "    return np.mean(row_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_0/gwtrw0ms65zdzng2095bbrdr0000gn/T/ipykernel_28746/2152131558.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fdata['candidate__w2v_hstack'] = fdata[\n",
      "/var/folders/_0/gwtrw0ms65zdzng2095bbrdr0000gn/T/ipykernel_28746/2152131558.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fdata['opportunity__w2v_vstack'] = fdata[\n",
      "/var/folders/_0/gwtrw0ms65zdzng2095bbrdr0000gn/T/ipykernel_28746/2152131558.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fdata['candidate__w2v_vstack'] = fdata[[m + \"__w2v\" for m in can_column] +\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gathering/concatenating the opportunity/job related vectors into a new column -\n",
    "Horizontal Stacking\n",
    "\"\"\"\n",
    "fdata['opportunity__w2v_hstack'] = fdata[\n",
    "    [m + \"__w2v\" for m in job_column]\n",
    "].apply(\n",
    "    hstacker, axis = 1\n",
    ")\n",
    "\n",
    "# Gathering/Concatenating the candidate related vectors into a new column\n",
    "fdata['candidate__w2v_hstack'] = fdata[\n",
    "    [m + \"__w2v\" for m in can_column]\n",
    "].apply(\n",
    "    hstacker, axis = 1\n",
    ")\n",
    "\n",
    "# Adding column 'Tag' to the candidate_w2v as it contains float values\n",
    "\n",
    "fdata['candidate__w2v_hstack'] = fdata[\n",
    "    ['candidate__w2v_hstack'] + ['Tag__w2v']\n",
    "].apply(\n",
    "    hstacker, axis = 1\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Gathering/concatenating the opportunity/job related vectors into a new column -\n",
    "Vertical Stacking\n",
    "\"\"\"\n",
    "fdata['opportunity__w2v_vstack'] = fdata[\n",
    "    [m + \"__w2v\" for m in job_column]\n",
    "].apply(\n",
    "    vstacker, axis = 1\n",
    ")\n",
    "\n",
    "# Gathering/Concatenating the candidate related vectors into a new column\n",
    "# Adding column 'Tag' to the candidate_w2v as it contains float values\n",
    "fdata['candidate__w2v_vstack'] = fdata[[m + \"__w2v\" for m in can_column] + \n",
    "['Tag__w2v']].apply(\n",
    "    vstacker, axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.3 Saving data for futher analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting rdata to a pickle file\n",
    "\n",
    "\"\"\" \n",
    "Creating featurizeddata_w2v that caries all the applicant, opportunity \n",
    "related vectors\n",
    "\"\"\"\n",
    "\n",
    "fdata[\n",
    "  [\"opportunity__w2v_hstack\"] + [\"candidate__w2v_hstack\"] + \n",
    "  [\"opportunity__w2v_vstack\"] + [\"candidate__w2v_vstack\"]\n",
    "].to_pickle(\n",
    "    dataloc + \"/interim/featurizeddata_w2v.pkl\"\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
